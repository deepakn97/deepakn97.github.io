---
---

@string{aps = {American Physical Society,}}

@inproceedings{DBLP:conf/icml/SharmaNK18,
  author    = {Charu Sharma and
               Deepak Nathani and
               Manohar Kaul},
  title     = {Solving Partial Assignment Problems using Random Clique Complexes},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {4593--4602},
  year      = {2018},
  crossref  = {DBLP:conf/icml/2018},
  url       = {http://proceedings.mlr.press/v80/sharma18a.html},
  timestamp = {Fri, 13 Jul 2018 14:58:25 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icml/SharmaNK18},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract  = {We present an alternate formulation of the partial assignment problem as matching random clique complexes, that are higher-order analogues of random graphs, designed to provide a set of invariants that better detect higher-order structure. The proposed method creates random clique adjacency matrices for each k-skeleton of the random clique complexes and matches them, taking into account each point as the affine combination of its geometric neighbourhood. We justify our solution theoretically, by analyzing the runtime and storage complexity of our algorithm along with the asymptotic behaviour of the quadratic assignment problem (QAP) that is associated with the underlying random clique adjacency matrices. Experiments on both synthetic and real-world datasets, containing severe occlusions and distortions, provide insight into the accuracy, efficiency, and robustness of our approach. We outperform diverse matching algorithms by a significant margin.},
  abbr      = {ICML},
  arxiv     = {arxiv:1907.01739},
  code      = {https://github.com/charusharma1991/RandomCliqueComplexes_ICML2018},
  blog      = {https://medium.com/@charusharma1991/graph-matching-partial-assignment-problem-using-random-clique-complexes-59aef2bf7b57}
}

@inproceedings{KBGAT2019,
  author    = {Deepak Nathani and Jatin Chauhan and Charu Sharma and Manohar Kaul},
  title     = {Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  location  = {Florence, Italy},
  abstract  = {The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multihop relations in our model. Our empirical study offers insights into the efficacy of our attention based model and we show marked performance gains in comparison to state of the art methods on all datasets.},
  abbr      = {ACL},
  arxiv     = {arxiv:1906.01195},
  blog      = {https://www.dnathani.net/blog/2019/Knowledge-Base-Relation-Prediction/},
  code      = {https://github.com/deepakn97/relationPrediction}
}

@inproceedings{Chauhan2020FEW-SHOT,
  title     = {Few-Shot Learning on Graphs via Super-Classes Based on Graph Spectral Measures},
  author    = {Jatin Chauhan and Deepak Nathani and Manohar Kaul},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=Bkeeca4Kvr},
  abstract  = {We propose to study the problem of few shot graph classification in graph neural networks (GNNs) to recognize unseen classes, given limited labeled graph examples. Despite several interesting GNN variants being proposed recently for node and graph classification tasks, when faced with scarce labeled examples in the few shot setting, these GNNs exhibit significant loss in classification performance. Here, we present an approach where a probability measure is assigned to each graph based on the spectrum of the graphs normalized Laplacian. This enables us to accordingly cluster the graph base labels associated with each graph into super classes, where the Lp Wasserstein distance serves as our underlying distance metric. Subsequently, a super graph constructed based on the super classes is then fed to our proposed GNN framework which exploits the latent inter class relationships made explicit by the super graph to achieve better class label separation among the graphs. We conduct exhaustive empirical evaluations of our proposed method and show that it outperforms both the adaptation of state of the art graph classification methods to few shot scenario and our naive baseline GNNs. Additionally, we also extend and study the behavior of our method to semi supervised and active learning scenarios.},
  abbr      = {ICLR},
  arxiv     = {arxiv:2002.12815},
  code      = {https://github.com/chauhanjatin10/GraphsFewShot},
  blog      = {https://medium.com/@cs17btech11019/few-shot-learning-on-graphs-f6312a9e9de5}
}

@inproceedings{10.1007/978-3-030-36687-2_3,
  author    = {Sumit Bhatia and Bapi Chatterjee and Deepak Nathani and Manohar Kaul},
  title     = {A Persistent Homology Perspective to the Link Prediction Problem},
  booktitle = {Complex Networks and Their Applications VIII},
  year      = {2020},
  publisher = {Springer International Publishing},
  pages     = {27--39},
  abstract  = {Persistent homology is a powerful tool in Topological Data Analysis (TDA) to capture topological properties of data succinctly at different spatial resolutions. For graphical data, shape and structure of the neighborhood of individual data items (nodes) is an essential means of characterizing their properties. We propose the use of persistent homology methods to capture structural and topological properties of graphs and use it to address the problem of link prediction. We achieve encouraging results on nine different real-world datasets that attest to the potential of persistent homology based methods for network analysis.},
  pdf       = {http://sumitbhatia.net/papers/complex-nets-19.pdf}
}

@inproceedings{krishna-etal-2022-shot,
  title     = {Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings},
  author    = {Krishna, Kalpesh  and
               Nathani, Deepak  and
               Garcia, Xavier  and
               Samanta, Bidisha  and
               Talukdar, Partha},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.514},
  doi       = {10.18653/v1/2022.acl-long.514},
  pages     = {7439--7468},
  abstract  = {Style transfer is the task of rewriting a sentence into a target style while approximately preserving content. While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al. 2021) has attempted {``}few-shot{''} style transfer using only 3-10 sentences at inference for style extraction. In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim. We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages. Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob. We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model. Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages. To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations.},
  abbr      = {ACL},
  pdf       = {https://aclanthology.org/2022.acl-long.514.pdf},
  arxiv     = {arxiv:2110.07385},
  website   = {https://martiansideofthemoon.github.io/2022/03/03/acl22.html},
  slides    = {https://docs.google.com/presentation/d/1PGk58vWuHP3FBt8EBA_aN9juo3gPPObAVhshwS3Rpkg/edit?resourcekey=0-Ma8fX94-cdv4SHTIpsFajw#slide=id.p}
}

@inproceedings{10.1145/3503252.3531301,
  author    = {Vardhan, Madhurima and Hegde, Narayan and Merugu, Srujana and Prabhat, Shantanu and Nathani, Deepak and Seneviratne, Martin and Muhammad, Nur and Reddy, Pranay and Lakshminarasimhan, Sriram and Singh, Rahul and Lorenzana, Karina and Motwani, Eshan and Talukdar, Partha and Raghuveer, Aravindan},
  title     = {Walking with PACE - Personalized and Automated Coaching Engine},
  year      = {2022},
  isbn      = {9781450392075},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3503252.3531301},
  doi       = {10.1145/3503252.3531301},
  abstract  = {We design and implement a personalized and automated physical activity coaching engine, PACE, which uses the Fogg’s behavioral model (FBM) to engage users in mini-conversation based coaching sessions. It is a chat-based nudge assistant that can boost (encourage) and sense (ask) the motivation, ability and propensity of users to walk and help them in achieving their step count targets, similar to a human coach. We demonstrate the feasibility, effectiveness and acceptability of PACE by directly comparing to human coaches in a Wizard-of-Oz deployment study with 33 participants over 21 days. We tracked coach-participant conversations, step counts and qualitative survey feedback. Our findings indicate that the PACE framework strongly emulated human coaching with no significant differences in the overall number of active days, step count and engagement patterns. The qualitative user feedback suggests that PACE cultivated a coach-like experience, offering barrier resolution via motivational and educational support. We use traditional human-computer interaction approaches, to interrogate the conversational data and report positive PACE-participant interaction patterns with respect to addressal, disclosure, collaborative target settings, and reflexivity. As a post-hoc analysis, we annotated the conversation logs from the human coaching arm and trained machine learning (ML) models on these data sets to predict the next boost (AUC 0.73 ± 0.02) and sense (AUC 0.83 ± 0.01) action. In future, such ML-based models could be made increasingly personalized and adaptive based on user behaviors.},
  booktitle = {Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization},
  pages     = {57–68},
  numpages  = {12},
  keywords  = {persuasive models, Automated assistant, behavior science, fitness coaching, personalization},
  location  = {Barcelona, Spain},
  series    = {UMAP '22},
  abbr      = {UMAP},
  pdf       = {https://dl.acm.org/doi/pdf/10.1145/3503252.3531301}
}

@misc{nathani2023maf,
  title         = {MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models},
  author        = {Deepak Nathani and David Wang and Liangming Pan and William Yang Wang},
  abstract      = {Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through self-improvement using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose Multi-Aspect Feedback, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see a relative improvement of up to 20% in Mathematical Reasoning and up to 18% in Logical Entailment.},
  year          = {2023},
  eprint        = {2310.12426},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  abbr          = {EMNLP},
  arxiv         = {arxiv:2310.12426},
  code          = {https://github.com/deepakn97/MAF/tree/main}
}
@inproceedings{10605442,
  author    = {Vardhan, Madhurima and Nathani, Deepak and Vardhan, Swarnima and Aggarwal, Abhinav and Simini, Filippo},
  booktitle = {2024 IEEE Conference on Artificial Intelligence (CAI)},
  title     = {Large language models as synthetic electronic health record data generators},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {804-810},
  keywords  = {Data privacy;Protocols;Large language models;Data models;Regulation;Generators;Reliability;Large language models;synthetic data;electronic health record data;generative adversarial network;generative models},
  doi       = {10.1109/CAI59869.2024.00152},
  abbr      = {CAI}
}
@article{10.1162/tacl_a_00660,
  author   = {Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  title    = {Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies},
  journal  = {Transactions of the Association for Computational Linguistics},
  volume   = {12},
  pages    = {484-506},
  year     = {2024},
  month    = {05},
  abstract = {While large language models (LLMs) have shown remarkable effectiveness in various NLP tasks, they are still prone to issues such as hallucination, unfaithful reasoning, and toxicity. A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output. Techniques leveraging automated feedback—either produced by the LLM itself (self-correction) or some external system—are of particular interest as they make LLM-based solutions more practical and deployable with minimal human intervention. This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches. We also identify potential challenges and future directions in this emerging field.},
  issn     = {2307-387X},
  doi      = {10.1162/tacl_a_00660},
  url      = {https://doi.org/10.1162/tacl\_a\_00660},
  eprint   = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00660/2369509/tacl\_a\_00660.pdf},
  abbr     = {TACL}
}
@misc{nathani2025mlgymnewframeworkbenchmark,
  title         = {MLGym: A New Framework and Benchmark for Advancing AI Research Agents},
  author        = {Deepak Nathani and Lovish Madaan and Nicholas Roberts and Nikolay Bashlykov and Ajay Menon and Vincent Moens and Amar Budhiraja and Despoina Magka and Vladislav Vorotilov and Gaurav Chaurasia and Dieuwke Hupkes and Ricardo Silveira Cabral and Tatiana Shavrina and Jakob Foerster and Yoram Bachrach and William Yang Wang and Roberta Raileanu},
  year          = {2025},
  eprint        = {2502.14499},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2502.14499},
  abbr          = {arXiv},
  code          = {https://github.com/facebookresearch/MLGym},
  abstract      = {We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for evaluating and developing LLM agents on AI research tasks. This is the first Gym environment for machine learning (ML) tasks, enabling research on reinforcement learning (RL) algorithms for training such agents. MLGym-bench consists of 13 diverse and open-ended AI research tasks from diverse domains such as computer vision, natural language processing, reinforcement learning, and game theory. Solving these tasks requires real-world AI research skills such as generating new ideas and hypotheses, creating and processing data, implementing ML methods, training models, running experiments, analyzing the results, and iterating through this process to improve on a given task. We evaluate a number of frontier large language models (LLMs) on our benchmarks such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5 Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate models or agents, generate synthetic data at scale, as well as develop new learning algorithms for training agents on AI research tasks. We find that current frontier models can improve on the given baselines, usually by finding better hyperparameters, but do not generate novel hypotheses, algorithms, architectures, or substantial improvements. We open-source our framework and benchmark to facilitate future research in advancing the AI research capabilities of LLM agents.},
  website       = {https://sites.google.com/view/mlgym},
  discord       = {https://discord.gg/jq442FGSD},
  arxiv         = {arxiv:2502.14499},
  slides        = {https://drive.google.com/file/d/1jyihti9eLdrvnuju8sR8l56GVbv3GdaA/view?usp=drive_link}
}