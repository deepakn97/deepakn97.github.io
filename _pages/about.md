---
layout: about
title: About
permalink: /
subtitle: # <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

<!-- modify this section to include main research interests -->
Hello! I am Deepak Nathani. I am currently a 3rd year PhD student at [UC, Santa Barbara](https://www.cs.ucsb.edu/) advised by [Prof. William Wang](https://sites.cs.ucsb.edu/~william/) in the [UCSB NLP](http://nlp.cs.ucsb.edu/) lab. My research revolve around the field of Natural Language Generation, with a focus on Reasoning in LLMs, Tool Use and Autonomous Agents. During my PhD, I have been fortunate to intern at [GenAI at Meta](https://ai.meta.com/) and [AWS Translate](https://www.amazon.science/).

Before joining the PhD program, I worked as a **Pre-Doctoral Researcher** at [Google Research, India](https://research.google/locations/india/) where I was advised by [Dr. Partha Talukdar](https://research.google/people/ParthaTalukdar/). At Google, I worked on Controllable Text Generation and Conversational AI. I also did a brief stint as a **Software Engineering AMTS** at [Salesforce.com](https://www.salesforce.com/).

I graduated from [IIT Hyderabad](https://iith.ac.in/) with a B.Tech degree in Mechanical Engineering and Computer Science as my second major. During my time as an undergraduate, I worked on various research problems with [Dr. Manohar Kaul](https://manukaul.github.io/).

Among other things, I enjoy playing games, listening to music, reading books and most important of them all, I love food. :wink:

<!-- Add Career Philosophy -->

### **Research**

I am interested in developing frameworks and methods to enhance the capabilities of large language models through automated feedback, tool use, and their applications in accelerating scientific discovery. My work is anchored in the following themes:

1. **AI Research Agents and Tool Use**: Developing frameworks for autonomous AI agents [[Preprint](https://arxiv.org/abs/2502.14499)] that can effectively use tools and improve their reasoning abilities through structured feedback mechanisms [EMNLP 2023](https://arxiv.org/abs/2310.12426).
2. **Controllable Text Generation**: Developing methods for controlled text generation in multilingual and low-resource settings [[ACL 2022](https://arxiv.org/abs/2110.07385)] to make text generation more accessible across different languages and domains.
3. **Healthcare and Behavior Science Applications**: Creating personalized coaching systems and synthetic data generation methods for healthcare applications while ensuring privacy and ethical considerations. [PLOS Digital Health 2024](https://doi.org/10.1371/journal.pdig.0000431), [IEEE CAI 2024](https://ieeexplore.ieee.org/document/10478000), [UMAP 2022](https://dl.acm.org/doi/10.1145/3503252.3531308).
4. **Graph Learning and Knowledge Graphs**: Investigating novel approaches to graph representation learning and knowledge graph completion [[ACL 2019](https://arxiv.org/abs/1906.01195)] using few-shot learning [[ICLR 2020](https://arxiv.org/abs/2002.12815)] and topological methods [Complex Networks 2019](https://link.springer.com/chapter/10.1007/978-3-030-36687-2_3), [ICML 2018](https://proceedings.mlr.press/v80/sharma18a.html).
